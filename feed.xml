<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-06-22T21:57:13+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">blank</title><subtitle>Ben Barlow&apos;s personal website
</subtitle><entry><title type="html">AI Perception Gap: The Journey Concludes</title><link href="http://localhost:4000/blog/2025/apg-blog-closing-statement/" rel="alternate" type="text/html" title="AI Perception Gap: The Journey Concludes" /><published>2025-06-07T06:40:16+01:00</published><updated>2025-06-07T06:40:16+01:00</updated><id>http://localhost:4000/blog/2025/apg-blog-closing-statement</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-closing-statement/"><![CDATA[<h2 id="ai-perception-gaps-aim">AI Perception Gap’s Aim</h2>

<p>This blog concludes the six-part <a href="https://ben-j-barlow.github.io/blog/tag/ai-perception-gap/">AI Perception Gap</a> series I introduced in November 2024. In that <a href="https://ben-j-barlow.github.io/blog/2024/ai-perception-gap-introducing-my-new-blog/">first entry</a>, I expressed my <strong>astonishment at Gen Z’s perception of AI</strong> — observed during a backpacking trip to Latin America — with this reflection:</p>

<p><em>Educated individuals, from my very generation (not my grandparents!), who were born and raised in wealthy economies where AI is booming, and no one had a clue about the monumental positive impact the technology can and will have on society at a global scale! The perception gap was born…</em></p>

<p>The problem? Most of Gen Z’s perception was built by <strong>mainstream media’s doom-and-gloom</strong> obsession. In Latin America, I found myself discussing AI’s positive potential with backpacker after backpacker. Watching their attitudes transform from <strong>fear to fascination</strong> was so rewarding that I felt compelled to <strong>amplify this mission</strong> through blogging. My goal was crystal clear: make my friends and the rest of Gen Z <strong>aware of the positive potential of AI</strong> and prove that “AI” doesn’t automatically mean “killer robots destined to destroy humanity”.</p>

<hr class="dots" />

<h2 id="positive-impacting-ai">Positive Impacting AI</h2>

<p>Since announcing my aim in November 2024, I’ve addressed the AI Perception Gap by showing that, when aligned with human goals, AI can:</p>

<ol>
  <li><strong>identify human fragments</strong> in the aftermath of a plane crash (<a href="https://ben-j-barlow.github.io/blog/2024/apg-blog-01/">edition 1</a>),</li>
  <li>assist with <strong>discovering critical minerals</strong> (<a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-02/">edition 2</a>),</li>
  <li>decode the structures of over 200 million proteins, <strong>reinventing drug discovery</strong> (<a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-04/">edition 4</a>),</li>
  <li>uncover the atomic blueprint of <strong>materials</strong> that could <strong>reshape entire industries</strong> (<a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-06/">edition 6</a>).</li>
</ol>

<p>In each case, AI accomplished what human cognition alone couldn’t — or what would have required the coordination of millions of superhuman brains. The world’s most brilliant scientists spend a lifetime mastering just one domain, often with little exposure to others. AI, on the other hand, achieves superhuman performance in one field at one moment, and seamlessly shifts to another field — with equally impressive performance — the next. This level of cross-domain proficiency isn’t just impressive — <strong>it’s the very essence of what makes AI revolutionary</strong>.</p>

<hr class="dots" />

<h2 id="negative-impacting-ai">Negative Impacting AI</h2>

<p>While most of this series explored AI’s positive potential, editions 3 and 5 addressed its risks. This was necessary since closing the AI Perception Gap requires the confrontation of Gen Z’s fears.</p>

<p>I categorise these into <strong><em>loud fears</em></strong>  — AGI going full sci-fi villain — and <strong><em>quiet fears</em></strong> — like hidden algorithmic bias embedded in decision-making systems.</p>

<p>In <a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-03/">edition 3</a>, we explored how <strong>AI can quietly reinforce inequality</strong> (a quiet fear). PredPol, a policing tool built with good intentions, was trained on biased historical data and repeatedly deployed officers into already over-policed communities. The designers had noble goals but made a crucial oversight — they didn’t account for how their data reflected existing social inequalities. As AI systems become woven into the fabric of public life, we desperately need designers who understand both the mathematics of machine learning and the messy realities of human society.</p>

<p><a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-05/">Edition 5</a>, on the other hand, leaned into the fear most often voiced by Gen Z: AGI with lethal autonomy. We imagined a system that identifies threats from satellite feeds, drafts tactical plans, and executes strikes with drone swarms — all without human input. Gen Z’s fear is valid, but this reality is not destiny. What gives me <strong>hope</strong> is that <strong>democratic nations</strong> are treating this like nuclear tech: seriously, cautiously, and collaboratively, with guardrails already taking shape. Just as nuclear deterrence has prevented catastrophe for decades, coordinated regulation and transparent safety efforts can do the same for AGI.</p>

<hr class="dots" />

<h2 id="did-ai-perception-gap-achieve-its-aim">Did AI Perception Gap Achieve It’s Aim?</h2>

<p>That’s for <strong>you</strong>, the reader, to answer! If you’re still reading at my eigth (and final!) entry, I’d love to hear how your perceptions changed during the series. I’ve spent over 100 hours on this project; any sense of reward would no doubt put a smile on my face!</p>

<p>Anyhow, I hope you too were smiling whilst reading: <strong>AI Perception Gap, over and out.</strong></p>]]></content><author><name></name></author><category term="ai-perception-gap" /><category term="reflection" /><summary type="html"><![CDATA[A reflection on the six-part series that aimed to address the gap in Gen Z's perception of AI.]]></summary></entry><entry><title type="html">AI Perception Gap: Atomic Architects — How AI is Redesigning Our Physical World</title><link href="http://localhost:4000/blog/2025/apg-blog-06/" rel="alternate" type="text/html" title="AI Perception Gap: Atomic Architects — How AI is Redesigning Our Physical World" /><published>2025-06-06T06:40:16+01:00</published><updated>2025-06-06T06:40:16+01:00</updated><id>http://localhost:4000/blog/2025/apg-blog-06</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-06/"><![CDATA[<h2 id="the-materials-we-desperately-need">The Materials We Desperately Need</h2>

<h4 id="material-dreamland">Material Dreamland</h4>
<p>Imagine a world where long-distance power lines lose no energy, electric cars charge in seconds, quantum computers hum away in every research lab, and frictionless, levitating trains zip between continents at blistering speeds. Discovering a <strong>room-temperature superconductor</strong>, a material referred to as the <strong>‘holy grail’ of physics</strong>, would be nothing short of revolutionary. But achieving it isn’t just about genius scientists in labs; it’s increasingly about AI working alongside them to redefine the limits of <strong>materials science</strong>.</p>

<p>Suppose a researcher were to imagine a shopping list of desired properties for a material capable of transforming an entire industry (e.g., plastic that biodegrades quickly). Could AI design the desired material’s atomic structure, use a digital model to prove the material has the desired properties, and even produce the material in the real world? In the paragraphs ahead, we’ll explore how academics and pioneering companies at the forefront of materials science are transforming our physical world with AI.</p>

<h4 id="what-is-a-superconductor">What is a superconductor?</h4>

<p>Firstly, a <strong><em>conductor</em></strong> is a material that allows <strong>electric current to flow</strong>. As you may recall from physics lessons at school, electric current is essentially the <strong>movement of electrons</strong> — however, this movement isn’t perfectly efficient. As electrons travel through a conductor — like the copper wiring found in household electrical circuits — they sometimes collide with vibrating atoms in the material. These collisions cause some of the electrical energy to be converted into heat — this is known as <strong><em>electrical resistance</em></strong>. The longer the wire, the more collisions occur, and the more energy is lost as heat.</p>

<p>A <strong><em>superconductor</em></strong>, on the other hand, is a special type of conductor in which this energy loss does not occur. The phenomenon was first discovered in 1911, when Dutch physicist Heike Kamerlingh Onnes cooled solid mercury to -270°C and observed that its electrical resistance disappeared entirely. Since then, scientists have identified various materials that become superconductors when cooled below a specific threshold, known as their <em>critical temperature</em>.</p>

<h4 id="why-would-a-room-temperature-superconductor-be-transformational">Why would a room-temperature superconductor be transformational?</h4>

<p>A <strong><em>room-temperature superconductor</em></strong> is a material that offers zero electrical resistance in ambient conditions. The material doesn’t need to be cooled to extreme <strong>temperatures</strong> or operate at a demanding air <strong>pressure</strong> for electrical resistance to vanish. Such a development has immense potential, especially in our transition to a <strong>renewable energy grid</strong>.</p>

<p>We’ve designed our energy system to keep the wires short: move the fossil fuels close to the cities, burn them there, and distribute the electricity locally.</p>

<p>With renewables, we cannot transport sunlight and wind to city-based power plants in the same way we can fossil fuels. We are instead forced to create electricity in the deserts, oceans, and mountain ranges rich with renewable sources. The primary obstacle to achieving a fully renewable grid is not the availability of natural resources, but the challenge of transmitting electricity over extremely long distances. Electrical resistance at that scale is not just inefficient; it’s a dealbreaker.</p>

<p>Room-temperature superconductors would change this entirely. Electricity could travel thousands of kilometres without any loss. We could harness <strong>solar power from the Sahara, wind in the North Sea, hydro in the Alps, and transmit it all over Europe without waste</strong>. It’s not just an upgrade — it would be a redefinition of what’s possible in global energy systems.</p>

<p>And that’s just one application of one material. A room-temperature superconductor could revolutionise computing, transportation, energy storage, and healthcare, to name a few. All the while, material scientists are hunting for many other transformational materials, such as biodegradable packaging, high energy density batteries, and self-cleaning surfaces (to repel contaminants in medical implants).</p>

<hr class="dots" />

<h2 id="material-science">Material Science</h2>

<p>To understand how we could discovery breakthrough materials like these, we turn to materials science — a field that blends physics, chemistry, and engineering to <strong>explain why materials behave the way they do</strong>. Material scientists study how atoms respond to forces or environments depending on their arrangement. This understanding allows us to achieve specific functions for materials by tailoring the arrangement of atoms.</p>

<p>Of particular importance are <strong><em>stable materials</em></strong>, often called crystals. Stability is linked to the energy required to break bonds or trigger chemical changes. Material stability is crucial because unstable substances degrade, deform, or react unpredictably, limiting their usefulness in engineering and design.</p>

<p>Think of a stable material as a calm person in a crisis — someone who stays composed even under pressure, heat, or chaos. The person who remains calmest is considered the most stable. In material science, the most stable materials are prized for everything from spacecraft to smartphones. These are the materials that scientists hope to discover.</p>

<hr class="dots" />

<h2 id="discovering-new-materials">Discovering New Materials</h2>

<h4 id="trial-error-and-centuries-of-waiting">Trial, Error, and Centuries of Waiting</h4>

<p>At the field’s inception, material scientists discovered new materials through <strong>trial and error</strong>. Early ironworkers discovered that iron, when heated in charcoal, became stronger and harder. The heating process caused carbon from charcoal to diffuse into the surface of iron, leading to the production of <strong>primitive forms of steel</strong>. This discovery occurred during the Iron Age (long before atomic structure of a material could be understood), with evidence of steel production found in Anatolia (modern-day Turkey) as early as 13th century BC. </p>

<p>As the field progressed, material scientists used <strong>intuition</strong> to develop new materials. For instance, if a certain oxide had useful properties, they’d try similar oxides with other elements. Further, materials were often discovered by subjecting elements to extreme conditions, in terms of temperature and pressure, and observing unexpected behaviors.</p>

<p>From the late 19th century, <strong>microscopic technology</strong> allowed scientists to see microstructures and atomic arrangements. These helped correlate structure with properties, for example, why certain alloys were tougher or more malleable.</p>

<h4 id="computational-methods">Computational Methods</h4>

<p>Following the introduction of the computer in the 1950s, <strong>computational materials science</strong> garnered increasing attention. By the 1970s, scientists were able to <strong>predict the properties</strong> of solid-state materials digitally using an algorithm called <strong>density functional theory (DFT)</strong>. Given the atomic structure, scientists could understand the material without having to physically create it in the real world.</p>

<p>Initially, the electronic, magnetic, and chemical properties of simple materials could be predicted using DFT with relative ease. As computational power increased, materials scientists began modeling the behavior of far more complex substances. A landmark example of DFT’s impact was its accurate prediction of the exceptional electronic properties of silicon. This insight fueled a surge of research in the 1980s — and now, silicon is at the heart of the memory and processing chips in the device you’re using to read this blog.</p>

<hr class="dots" />

<h2 id="ai-unleashed-the-discovery-explosion">AI Unleashed: The Discovery Explosion</h2>

<p><strong>Google DeepMind</strong> (introduced in <a href="https://ben-j-barlow.github.io/blog/2025/apg-blog-04/">AI Perception Gap: Unlocking Biology’s Secrets with AlphaFold</a>) is working at the cutting edge of this field. Its AI model, GNoME, <strong>identified 2.2 million potential crystal structures</strong> — unique atomic arrangements predicted to be stable. Of these, 380,000 are classified as highly stable. For context, <strong>humans discovered around 20,000</strong> stable crystals through experimentation since early pioneers discovered steel in the Iron Age. Computational methods later expanded our stable materials universe to 48,000. GNoME has <strong>nearly tenfolded</strong> this number, taking us past 400,000 — massively boosting our chances of finding breakthroughs like a room-temperature superconductor.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_06_gnome_discoveries.webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_06_gnome_discoveries.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A venn diagram showing that GNoME has produced 421,000 stable materials compared to 48,000 produced with previous computational methods" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>About 20,000 of the crystals experimentally identified in the ICSD database are computationally stable. Computational approaches drawing from the Materials Project, Open Quantum Materials Database and WBM database boosted this number to 48,000 stable crystals. GNoME expands the number of stable materials known to humanity to 421,000. Image credit: <a href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning">Google DeepMind</a>.</figcaption>
</figure>

<p>Although promising new materials can be identified at scale
with technology, synthesising them in the real world is
often challenging and time-consuming. As of November 2023, scientists had produced 736 of the 421,000 candidates shared by DeepMind. That may seem like a drop in the ocean, but it marks meaningful progress. Thanks to digital tools that estimate how promising a material might be, researchers can prioritise only the most likely successes for real-world synthesis.</p>

<p>Even more impressively, robots are now helping turn theory into reality. At Berkeley Lab’s A-Lab, <strong>AI-driven robots work 24/7 to create materials</strong> in powder form in the real world. The lab begins by selecting candidate compounds identified through AI tools at Google DeepMind and other organisations. Language models (think ChatGPT) trained on vast materials science corpora then generate detailed experimental protocols. Then, <strong>robotic systems follow these recipes</strong> in fully automated workflows — measuring, heating, mixing, and analysing compounds with machine precision. In a <a href="https://www.nature.com/articles/s41586-023-06734-w">published study</a>, A-Lab reported synthesising 41 out of 58 materials in 17 days.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_06_berk_lab.webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_06_berk_lab.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A robotic arm at synthesising new materials in a lab" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>A-Lab, a facility at Berkeley Lab, USA, where artificial intelligence guides robots in making new materials. Image credit: Marilyn Sargent/Berkeley Lab.</figcaption>
</figure>

<p>Let that sink in: AI dreamed up a material that never existed, predicted how it would behave, devised the instructions to synthesise it in our physical world, and then guided a robot to bring it into existence.</p>

<hr class="dots" />

<h2 id="the-age-of-inverse-engineering">The Age of Inverse Engineering</h2>

<p>With advancements being made from research groups and innovative companies around the world, <strong>inverse design</strong> is set to become the pinnacle of computational materials science. The desired properties — like high electrical conductivity, thermal stability, or optical transparency — are declared first, then AI selects the elements from the periodic table and the required structure to achieve the list of desired properties.</p>

<p>I invite the reader to spend 70 seconds listening to Pushmeet Kohli, VP of Science Research at Google DeepMind, discuss this vision.</p>

<figure class="post-figure">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/BfDACxrdAvQ?si=0fWI51LjEKv4k-hd&amp;start=855" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
    <figcaption>Pushmeet Kohli, VP of Science Research at Google DeepMind, discusses the future of materials science. I recommend listening for 70 seconds until timestamp 15:28.</figcaption>
</figure>

<h2 id="conclusion">Conclusion</h2>

<p><em>Okay, I am well over 100 hours deep of blog writing and I’m getting tired. It’s time for AI to write an entire paragraph in my final edition of my AI blog. I’m going to put my feet up.</em></p>

<p>From early blacksmithing to autonomous laboratories, the journey of materials science has always been shaped by the tools at our disposal. Today, AI and robotics are radically accelerating that journey — unlocking not just the promise of room-temperature superconductors, but a wide array of transformative innovations. We’re designing self-cleaning surfaces that repel contaminants in medical implants, high energy density batteries that could reshape electric mobility, and biodegradable packaging to address global sustainability challenges. The ability to explore millions of materials digitally — and rapidly test the most promising ones in the real world — means that breakthroughs once considered speculative are edging toward inevitability.</p>

<p>*This wraps up the AI Perception Gap; find a reflection on the six-part series <a href="/blog/2025/apg-blog-closing-statement/">here</a>.</p>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[From dreaming up new materials to building them with robots — AI is transforming our physical world.]]></summary></entry><entry><title type="html">AI Perception Gap: AGI and the Modern Cold War</title><link href="http://localhost:4000/blog/2025/apg-blog-05/" rel="alternate" type="text/html" title="AI Perception Gap: AGI and the Modern Cold War" /><published>2025-04-06T06:40:16+01:00</published><updated>2025-04-06T06:40:16+01:00</updated><id>http://localhost:4000/blog/2025/apg-blog-05</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-05/"><![CDATA[<h2 id="the-new-weapon-of-global-power-agi">The New Weapon of Global Power: AGI</h2>

<p>Imagine an AI that could debate philosophy, orchestrate strategic decisions in warfare, and pass the bar exam — all in the same afternoon. That’s the idea behind <strong>artificial general intelligence (AGI)</strong>: AI that can <strong>match or surpass human capabilities</strong> across <strong>many domains</strong> simultaneously.</p>

<p>We’re entering a new kind of arms race — one where intelligence, not firepower, decides the victor. And it’s already begun. While headlines focus on ChatGPT, DeepSeek, and productivity tools, nation-states are eyeing AGI for something far more consequential: <strong>global dominance</strong>.</p>

<p>In this blog, I explore why AGI is the engine behind a new geopolitical era. We’ll unpack how China’s <strong>DeepSeek moment</strong> shattered assumptions about US dominance, how AI warfare could mirror dystopian sci-fi, and why AGI demands the same global safeguards we built around nuclear weapons last century.</p>

<hr class="dots" />

<h2 id="agi-is-nothing-like-what-came-before">AGI Is Nothing Like What Came Before</h2>

<p>In past editions of <a href="http://127.0.0.1:4000/blog/tag/ai-perception-gap/">AI Perception Gap</a>, researchers at the Netherlands Forensic Institute (NFI) and Google DeepMind achieved incredible feats — one used AI to <a href="https://ben-j-barlow.github.io/blog/2024/apg-blog-01/">identify victims of a plane crash</a>, while the other <a href="https://ben-j-barlow.github.io/blog/2025/apg-blg-04/">found the structures of 200 million proteins</a>. But here’s the catch: DeepMind’s AI, trained in protein science, was useless at identifying human remains. Likewise, the forensic AI had no clue about proteins. These were both forms of <strong><em>tool AI</em></strong> — AI systems designed for one job and one job only.</p>

<p>While tool AIs are narrow in focus, <strong>AGI is the ultimate generalist</strong>. It’s not limited to one skill — it can think, adapt, and solve problems across <strong>countless domains</strong>. Like a human, only it can learn much more information, and learn it faster. It’s comparable to millions of human brains combining to form a single superbrain. AGI is the kind of system that could fold proteins in the morning and assist in forensic investigations by afternoon. It’s tough to grasp the potential, so let’s break it down with real-world possibilities.</p>

<p>Think about how we learn. AGI could revolutionise <strong>education</strong> by tailoring lessons to each individual student. It could track how fast they grasp concepts, what they find difficult, and how they prefer to learn. If connected to a camera, it could notice the student struggling or zoning out, using cues like facial expression or eye movement. This could mean students learning at their own rhythm, in ways that actually click — departing from traditional one-size-fits-all classrooms.</p>

<p>In the <strong>medical</strong> world, AGI could become a true genius — one that never tires, never loses focus, and works through the night without faltering. With next-generation devices continuously measuring hospital inpatient health data, AGI could absorb an entire hospital’s patient data in real-time, and direct doctors to where they’re most needed. With that level of insight, healthcare could shift towards preventing emergencies instead of just responding to them.</p>

<p>All the while, AGI could <strong>discover new theories</strong>, rewrite textbooks, and solve problems humans haven’t even thought of. Einstein, in 1915, changed physics forever by publishing his general theory of relativity. Combining his existing knowledge with impressive reasoning, he conceived new scientific principles and shared them with the world. But what if you handed AGI all the world’s knowledge up to 1914? Could it replicate Einstein’s work? Quite possibly. In fact, incredibly likely. Experts believe we’re <strong>less than a decade</strong> away from this level of machine intelligence.</p>

<p>Unlike tool AI, which is applied to a pre-defined task, AGI will have the freedom to make <strong>autonomous decisions across a wide range of challenges</strong> — just like a human.</p>

<p>AGI’s ramifications are endless — enough to fill a book, let alone a blog. But with global tensions mounting and drones already transforming war in Ukraine, this blog focuses on <strong>battlefield applications of AGI</strong> and the <strong>resulting AI cold war</strong>.</p>

<hr class="dots" />

<h2 id="export-control-or-illusion-of-control">Export Control or Illusion of Control?</h2>

<p>An application of AGI with huge potential is <strong>warfare</strong>. Think <em>Skynet</em> from <em>The Terminator</em> — an AI that launched nuclear attacks and turned on humanity. That’s science fiction, but the trajectory isn’t far off: AGI could process real-time satelitte data, pinpoint threats, and craft tactical strategies. And once planned, these strategies could be executed by swarms of autonomous drones or robot infantry. Every step, from <strong>satellite surveillance to surgical strike</strong>, could run in seconds <strong>without a single human</strong> intervening. The first country to master AGI won’t just lead — <strong>they’ll dominate</strong>.</p>

<p>The pursuit of AGI mirrors the nuclear arms race of the 20th century — but this time, the stakes stretch beyond deterrence. When one superpower (USA) is a democracy and the other (China) an authoritarian state, AGI <strong>amplifies global instability</strong>. Democracies are slowed by laws, public opinion, and ethical constraints. Authoritarian states? Move as fast as their capabilities allow.</p>

<p>In anticipation of AGI’s strategic value, the US acted early. On October 7, 2022, days before the release of ChatGPT sparked public interest in AI, the US set legislation to <strong>slow China’s AI advancements</strong>. The US banned the most powerful AI chips, hundreds of thousands of which are needed for an organisation to advance from today’s <strong><em>emerging AGI</em></strong> (like ChatGPT) towards AGI, from being exported to China. This move — which was about remaining a military, economic, and geopolitical superpower — birthed an <strong>AI chip cold war</strong>.</p>

<p>Since then, limited supply has created a booming <strong>black market</strong>. TikTok’s Chinese-based parent company ByteDance are known to circumvent export restrictions by renting access to AI chips housed in Southeast Asian data centres run by US firms. The US, realising this workaround, followed by imposing restrictions on allies in Asia and Europe. Oddly, it’s arguably easier for Singapore to <a href="https://armyrecognition.com/news/aerospace-news/2025/singapore-confirms-the-purchase-of-eight-more-f-35a-fighter-jets-to-complement-earlier-f-35b-acquisition">buy US F-35 fighter jets</a> than top US AI chips. Crazy.</p>

<p>One striking story was shared on the <a href="https://lexfridman.com/podcast/">Lex Fridman podcast</a>. A tech exec saw someone checking in to a <strong>first class</strong> flight from San Francisco to China with a box suspected to contain a handful of chips. The math is simple: buy some chips for $100k in the US, sell them for double in China, pocket the difference, and travel in luxury on the profits. It’s not just a market — it’s a lifestyle.</p>

<p>So it’s fair to ask — <strong>are these export controls enough?</strong> Can the US really expect to win the AGI race by blocking hardware? The next section dives into <strong>China’s DeepSeek breakthrough</strong>; a moment that suggests the <strong>answer might already be no</strong>.</p>

<figure class="post-figure">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/_1f-o0nqpEI?si=YGwZJvYSWGSziNGI&amp;start=12084" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
    <figcaption>Dylan Patel, a leader in the semiconductor industry, sharing a chip (called a "GPU" here) smuggling story on the Lex Fridman Podcast. I recommend listening for 46 seconds until 3:22:10.</figcaption>
</figure>

<h2 id="david-vs-goliath-deepseeks-breakthrough">David vs Goliath: DeepSeek’s Breakthrough</h2>

<p>The AI world will always remember January 20, 2025; the day the little-known Chinese startup DeepSeek announced themselves as <strong>a major AI player</strong>. Despite their AI chip access being choked by US restrictions, the AI they released on that day was ranked more intelligent than many US counterparts. Their timing, on the day <strong>Donald Trump was sworn in as president</strong>, felt like more than coincidence. Was it a message? <em>Two can play this AI game.</em></p>

<p>The explanation for how DeepSeek was able to compete on the world stage lies in their DNA. <strong>Their CEO, Liang Wenfeng</strong> — a long-time AI enthusiast — had been applying his passion in AI at his China-based hedge fund for years. Prior to US restrictions, in 2021, Wenfeng reportedly acquired 10,000 of the highest-performing chips. Back then, he and his hedge fund team used them solely to predict stock prices with AI.</p>

<p>In May 2023, Wenfeng solidified his passion for the field by founding DeepSeek, a research organisation entirely focused on AI. Using profits from his hedge fund’s $10+bn portfolio to bankroll DeepSeek, Wenfeng attracted China’s brightest AI minds with lucrative salaries. After adding thousands of less powerful chip alternatives, exempt from US restrictions, to his existing stockpile, Wenfeng and his team enhanced the <strong>efficiency</strong> of each chip through <strong>unprecedented innovation</strong>.</p>

<p>Their AI is built <strong>modularly</strong>, taking inspiration from the energy-preserving modular structure found in the human brain. Instead of the entire brain being active at once, the visual cortex activates when processing data from the eye, or the amygdala switches on in response to danger. Using a similar approach in AI is not new — OpenAI is thought to do the same — but DeepSeek does it differently. Additionally, DeepSeek created bespoke code to replace NVIDIA’s AI chip operating manual. Think of a manufacturer producing hundreds of cars. Instead of focussing on production volume and using a readily available factory-made gearbox, DeepSeek invested huge amounts of time to build their own hand-tuned racing transmission. US firms have also tinkered with the gearbox, but DeepSeek was the first to revolutionise AI models by doing so at an extreme level of detail.</p>

<p>Quite simply, without huge quantities of chips available, <strong>necessity became the mother of innovation</strong>. The result? A watershed moment. DeepSeek out-innovated those with unlimited resources, reinforcing existing doubts over the effectiveness of the US’s export restrictions. The DeepSeek moment is a metaphor for a wider narrative: <strong>If China can use limited compute and unlimited innovation to compete with the US’s early-stage AGI in 2025, will China be able to hold its own in the race to advanced AGI over the next five to ten years?</strong></p>

<hr class="dots" />

<h2 id="from-backpacker-fear-to-global-reality">From Backpacker Fear to Global Reality</h2>

<p>When I backpacked through Central America in 2022, <a href="https://ben-j-barlow.github.io/blog/2024/ai-perception-gap-introducing-my-new-blog/">conversations I had about AI</a> almost always ended in dystopian dread. To my fellow travellers, “AI” meant a self-aware system writing its own code, spiralling out of control, and inevitably turning on humanity. That misunderstanding — the AI Perception Gap — is exactly what inspired me to start this blog.</p>

<p>If they were reading this now, my fellow backpackers would be smug — “We called it!” AGI in warfare is about as dystopian as it gets. And honestly, their fears hold water: if global superpowers like the USA are deeply concerned about who reaches AGI first, then why shouldn’t the rest of us be?</p>

<p>I’d start by encouraging trust in governments. Nuclear weapons haven’t vanished, but global stability has held because of mutual deterrence. If democratic superpowers like the US are actively working towards obtaining AGI, then we have a great opportunity to navigate adoption of this technology safely.</p>

<p>Then there’s the unsettling question of non-state actors. Could a lone individual, armed with a powerful model, develop a weapon of mass destruction? <a href="https://www.anthropic.com">Anthropic</a>, the maker of ChatGPT rival Claude, is a pioneer in managing these risks — they run <strong>CBRN</strong> filters to determine if their products pose <strong>chemical, biological, radiological, or nuclear risks</strong>. They test if their AI could help a user learn to build a CBRN weapon, above and beyond what can be known from simply looking at Google. But it’s not just about what AI knows — it’s about what it could discover. Another concern arises when a model doesn’t just retrieve facts but actively generates novel methods, materials, or designs — AGI reasoning so well it produces a novel CBRN method, like Einstein proposing his relativity theory in 1915.</p>

<p>Anthropic doesn’t just sound the alarm by <a href="https://www.anthropic.com/news/challenges-in-red-teaming-ai-systems">posting about the lack of standardised practices</a>, they also call for action. They’ve <a href="https://www.anthropic.com/news/the-case-for-targeted-regulation">urged</a> lawmakers, tech leaders, and civil groups to come together and build a shared framework for regulation. With predictions suggesting we are one to two years from products like ChatGPT posing CBRN risks, their message is clear: <strong>AI safety isn’t optional — it’s urgent</strong>.</p>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[A gripping look into how artificial general intelligence could shift global power, with China’s DeepSeek moment as a turning point.]]></summary></entry><entry><title type="html">AI Perception Gap: Unlocking Biology’s Secrets with AlphaFold</title><link href="http://localhost:4000/blog/2025/apg-blog-04/" rel="alternate" type="text/html" title="AI Perception Gap: Unlocking Biology’s Secrets with AlphaFold" /><published>2025-03-06T05:40:16+00:00</published><updated>2025-03-06T05:40:16+00:00</updated><id>http://localhost:4000/blog/2025/apg-blog-04</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-04/"><![CDATA[<h2 id="a-new-era-of-biological-discovery">A New Era of Biological Discovery</h2>

<p><em>What if the recipe for eradicating all disease already exists — but we just don’t know where to look?</em></p>

<p>The world is riddled with <strong>preventable disease</strong>. Heart disease, cancer, neurodegenerative disorders, and type 2 diabetes claim <strong>millions of lives every year</strong>. If you’ve ever watched a loved one deteriorate from Alzheimer’s or cancer, you know the pain goes far beyond numbers.</p>

<p>At the heart of these diseases lies a common culprit: <strong>proteins</strong>. To cure and prevent diseases, we must understand thousands of proteins, their functions, and their structures. <strong>Finding the structure of a single protein used to take a PhD student their entire PhD — four to five years of painstaking work</strong>. The global effort of scientists over four decades uncovered the structures of just 0.075% of the 200 million proteins in the observed protein universe.</p>

<p>Enter <strong>Google DeepMind</strong>, a research company led by British-born Sir Demis Hassabis, a former chess prodigy turned AI visionary who, in 2024, was knighted for “services to artificial intelligence”. After years of building AI that could master board games at superhuman level, he directed DeepMind’s attention to structural biology. Using AI, his team reduced finding the structure of a protein <strong>from five years to a few seconds</strong>. Hailed by some as the greatest scientific breakthrough ever, their work has unlocked countless doors in medicine. Demis truly believes that with DeepMind’s AI already in the hands of every biologist worldwide, we will <strong>eradicate all disease on Earth</strong>.</p>

<h2 id="why-solve-the-protein-folding-problem">Why Solve the Protein Folding Problem?</h2>

<p><em>What was the exact problem Demis and DeepMind solved?</em></p>

<p><strong>The protein folding problem.</strong></p>

<p>Before introducing you to the protein folding problem, I’ll explain why solving it is the <strong>most significant structural biology breakthrough ever</strong>. It is a root node problem. Solve it, and an entire tree of challenges — in medicine, material science, and beyond — becomes easier to tackle.</p>

<p>For example, by solving protein folding, DeepMind has unlocked <strong>drug discovery</strong>. Most drugs work by binding, like a lock and key, to specific proteins — such as enzymes, receptors, ion channels, or transport proteins — to alter their function. To design effective drugs, scientists need to first map the structure of these proteins to identify binding sites. Just as crucial is understanding the structure of other proteins in the body to ensure the drug binds only to its intended target, minimising harmful side effects.</p>

<p>Before DeepMind’s breakthrough, the protein folding problem — marked amber because it was theoretically solvable, but yet to be solved — remained a critical bottleneck, blocking breakthroughs in fields that depended on it.</p>

<figure class="post-figure">
    <img style="width: 65%;" src="/assets/img/blog/2025/apg_04_spider1.png" alt="A diagram with protein folding at the center in yellow (solvable), branching into red-labeled (unsolvable) challenges like drug discovery and recycling plastic, alongside amber-labeled areas like vaccine design and disease understanding." />
    <figcaption>While protein folding remained unsolved (amber), major breakthroughs in fields that depended on understanding proteins' structures were near-impossible (red).</figcaption>
</figure>

<p>By solving the protein folding problem, dependencies have transitioned from near-impossible to solvable.</p>

<figure class="post-figure">
    <img style="width: 65%;" src="/assets/img/blog/2025/apg_04_spider2.png" alt="A diagram with protein folding at the center in yellow (solved), branching into amber-labeled (solvable) challenges like drug discovery and recycling plastic, alongside amber-labeled areas like vaccine design and disease understanding." />
    <figcaption>Solving protein folding (green) unlocked a cascade of breakthroughs in other fields (amber). While medicine stands to gain immensely, the impact extends much further — to fields like materials science and beyond.</figcaption>
</figure>

<p>The use of the solved–solvable–impossible framework in these diagrams is an intentional oversimplification. Scientists weren’t completely in the dark before; progress was still made in drug discovery,  disease understanding, and many other fields. But, progress was slow — after all, they only had structural knowledge of 0.075% of the protein universe. Now, armed with a complete structural understanding, these fields are accelerating into uncharted territory at an unprecedented pace.</p>

<p>Anyhow, let’s address the elephant in the room — <strong>what is the protein folding problem?</strong></p>

<h2 id="the-50-year-mystery-protein-folding">The 50-Year Mystery: Protein Folding</h2>

<p><strong>Proteins</strong> are made of amino acids. In nature, a sequence of amino acids <strong>folds</strong> intricately to create a 3D shape — a protein — like a string of beads forming a ball. A protein’s overall shape depends on the <strong>attractions and repulsions</strong> between all the atoms in the amino acids its made of. Some want to be together, some don’t. With all these chemical interactions at play, the number of possible fold configurations for a single protein is enormous — <strong>greater than the number of atoms in the observable universe</strong>.</p>

<p>When Christian Anfinsen won the 1972 Nobel Prize in Chemistry, he proposed a bold idea — given an amino acid sequence, it should be possible to predict its final structure. Biologists called this the <strong>protein folding problem</strong>, and for fifty years, it stood as one of the greatest <strong>unsolved mysteries in science</strong>. With
\(10^{300}\) possible fold configurations for an average protein (a staggering 301-digit number!), no human brain could hope to solve it. But where human cognition met its limits, Demis saw only inevitability — AI would succeed where biology had stalled.</p>

<figure class="post-figure" style="width: 80%;">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_04_sequence_to_protein-480.webp 480w,/assets/img/blog/2025/apg_04_sequence_to_protein-800.webp 800w,/assets/img/blog/2025/apg_04_sequence_to_protein-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_04_sequence_to_protein.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A diagram showing a sequence of amino acids folding to form a protein" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>Proteins are chains of amino acid molecules that form a 3D shape based on their atoms’ interactions. © Johan Jarnestad (The Royal Swedish Academy of Sciences)</figcaption>
</figure>

<h2 id="how-ai-solved-the-unsolvable">How AI Solved the Unsolvable</h2>

<p>After mastering board games by defeating world champions with AI during the 2010s, DeepMind looked for their next ticket to the world stage. In 2017, Demis hired Dr John Jumper — a chemist with a background in protein structure. Over the next five years, AI researchers at DeepMind tackled biology’s grand challenge, with repurposed board game algorithms.</p>

<p>Rather than selecting moves on a board, DeepMind’s protein-folding AI, <strong><em>AlphaFold</em></strong>, deciphered the <strong>fundamental rules governing protein folding</strong>. By analysing 150,000 protein structures catalogued by biologists over the last forty years, AlphaFold uncovered <strong>hidden patterns of attraction and repulsion</strong> within amino acid sequences. Now, with this unprecedented insight, it can <strong>predict a protein’s structure in seconds</strong>.</p>

<p>AlphaFold has now mapped the structures of <strong>over 200 million proteins</strong>. If solving a single structure through traditional methods took five years, then in sheer research output, DeepMind has <strong>completed a staggering 1 billion PhD years</strong>. But they didn’t keep this knowledge locked away — instead, they made every structure freely available in a vast public database. Today, rather than spending six figures hiring a PhD student on an arduous, years-long endeavor, biologists can retrieve a protein’s structure effortlessly via a Google search. DeepMind has elevated the entire scientific community, placing them atop the shoulders of a new kind of giant. That giant is AlphaFold, and it is as giant as they come.</p>

<h2 id="beyond-protein-folding-ais-expanding-role">Beyond Protein Folding: AI’s Expanding Role</h2>

<h3 id="ai-powered-drug-discovery">AI-Powered Drug Discovery</h3>

<p><strong>“I believe we are on the cusp of an incredible new era of biological and medical research,”</strong> said Demis on the Big Technology <a href="https://open.spotify.com/episode/1TdaC7eYBlnDQKMn55J5Ag?si=58aa80a7b277435f">podcast</a>.</p>

<p>To bring this vision to life, DeepMind launched AlphaFold spinout <strong>Isomorphic Labs</strong>, with Demis at the helm, to <strong>revolutionise drug discovery</strong>. Isomorphic isn’t stopping at protein structures — it aims to <strong>simulate entire cells</strong>, unlocking unprecedented possibilities. Instead of painstakingly growing cells in a lab and observing microscopic reactions, scientists will soon be able to <strong>inject virtual cells with drug candidates</strong> (they’re training AI to identify promising drug candidates too!) and observe the results — all within a computer simulation.  With the power to test <strong>millions of candidates in seconds</strong>, the pace of drug discovery is set to shatter every existing limit.</p>

<p>The final steps of drug discovery will remain unchanged; AI will not replace the need for <strong>laboratory validation or clinical trials</strong>. But with AI eliminating dead-end compounds early, the process will be dramatically faster and more cost-effective. This shift, which Demis believes the algorithms for which are just <strong>five years away</strong>, will mark a turning point for the entire pharmaceutical industry. He delves into the implications in a must-hear two-minute segment on the Big Technology podcast.</p>

<figure class="post-figure">
    <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/1TdaC7eYBlnDQKMn55J5Ag/video?utm_source=generator&amp;t=2500" width="496" height="279" frameborder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
    <figcaption>Demis predicts the drug discovery paradigm shift on the Big Technology podcast. I advise listening until timestamp 43:38.</figcaption>
</figure>

<h3 id="beyond-medicine-food-security-plastic-recycling--more">Beyond Medicine: Food Security, Plastic Recycling &amp; More</h3>

<p>AlphaFold is more than a breakthrough in medicine — it is a catalyst for change across industries. Below, I include compelling video summaries of its impact on agriculture and plastic recycling, along with a link to more groundbreaking applications shared by AlphaFold.</p>

<figure class="post-figure">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/dVfFKNz_L4E?si=JDqJX_TjAnYYsc2o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
    <figcaption>Up to 40% of global crop yields are lost to pests and diseases each year. This translates to billions of tons of food lost annually, posing a serious threat to global food security. Researchers at the University of Oxford, UK, are using AlphaFold to accelerate scientific research in making plants more resistant to diseases. One day, this work could help protect the world’s food supplies.</figcaption>
</figure>

<figure class="post-figure">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/QkYUGgnRbbE?si=so454ogWxxMX82Vw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
    <figcaption>The world produces around 400 million tonnes of plastic waste each year. Much of it ends up in landfill; a significant portion is polluting the world’s oceans. The Centre for Enzyme Innovation at the University of Portsmouth is using AlphaFold to realise their aim of a fully circular plastic economy. Using enzymes to break plastic polymers down so they can be 100% recycled back to their initial state.</figcaption>
</figure>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_04_case_studies-480.webp 480w,/assets/img/blog/2025/apg_04_case_studies-800.webp 800w,/assets/img/blog/2025/apg_04_case_studies-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_04_case_studies.png" class="img-fluid rounded z-depth-1" width="100px" height="auto" alt="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>Researchers are using AlphaFold in nearly every field of biology. Explore some of their stories <a href="https://deepmind.google/technologies/alphafold/impact-stories/">here</a>.</figcaption>
</figure>

<h2 id="a-scientific-earthquake-alphafolds-legacy">A Scientific Earthquake: AlphaFold’s Legacy</h2>

<p><em>If AlphaFold is so groundbreaking, why haven’t I heard about it before?</em></p>

<p>Because protein structure is a root node problem. If we cure cancer tomorrow, the news would be inescapable. But AlphaFold operates further upstream — solving a fundamental but less flashy piece of the puzzle. Take the BBC’s homepage today, for example. It featured an article titled <a href="https://www.bbc.com/news/articles/cpv4jww3r4eo">“Scientists discover new part of the immune system”</a>. No mention of AI, no mention of AlphaFold. Yet, did the scientists behind the discovery use AlphaFold, and did their <a href="https://www.nature.com/articles/s41586-025-08615-w">paper</a> join the 32,000 others that have cited DeepMind’s groundbreaking <a href="https://www.nature.com/articles/s41586-021-03819-2">study</a> in the past four years? Absolutely.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_04_bbc-480.webp 480w,/assets/img/blog/2025/apg_04_bbc-800.webp 800w,/assets/img/blog/2025/apg_04_bbc-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_04_bbc.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="The BBC homepage on Friday 6th March, 2025. An article in the top right" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>The BBC homepage on Friday 6th March, 2025. An <a href="https://www.bbc.com/news/articles/cpv4jww3r4eo">article</a> in the top right summarises a scientific study that used AlphaFold.</figcaption>
</figure>

<p>The AlphaFold protein database has been accessed by over 2 million researchers across 190 countries – every single biologist in the world, plus a few hundred thousand from other fields. This isn’t an incremental improvement — it’s an earthquake, a rewriting of the rules. That’s why Forbes declared it <a href="https://www.forbes.com/sites/robtoews/2021/10/03/alphafold-is-the-most-important-achievement-in-ai-ever/?sh=51afa9816e0a">“The Most Important Achievement in AI—Ever”</a>. That’s why <em>Science</em>, one of the most prestigious journals in the world, made an AlphaFold-inspired discovery a cover story. And that’s why Sir Demis Hassabis and Dr John Jumper were awarded the 2024 Nobel Prize in Chemistry.</p>

<figure class="post-figure" style="width: 50%;">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_04_nuclear_pore-480.webp 480w,/assets/img/blog/2025/apg_04_nuclear_pore-800.webp 800w,/assets/img/blog/2025/apg_04_nuclear_pore-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_04_nuclear_pore.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>A special edition of Science in June 2022, with the structural discovery of the important nuclear pore complex (made possible by AlphaFold) featured as a cover story.</figcaption>
</figure>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[From solving a 50-year grand challenge in biology to potentially eradicating all disease, this AI breakthrough is revolutionising medicine and beyond.]]></summary></entry><entry><title type="html">AI Perception Gap: AI Policing Reinforces and Exacerbates Societal Inequality</title><link href="http://localhost:4000/blog/2025/apg-blog-03/" rel="alternate" type="text/html" title="AI Perception Gap: AI Policing Reinforces and Exacerbates Societal Inequality" /><published>2025-02-06T05:40:16+00:00</published><updated>2025-02-06T05:40:16+00:00</updated><id>http://localhost:4000/blog/2025/apg-blog-03</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-03/"><![CDATA[<h2 id="the-ai-we-fear-vs-the-ai-we-miss">The AI We Fear vs. The AI We Miss</h2>

<p><em>“When the robots take over, I’m blaming you!”</em></p>

<p>I’d just mentioned my plans to pursue postgraduate studies in Artificial Intelligence whilst sitting in the bar of a Mexican hostel. As I <a href="https://ben-j-barlow.github.io/blog/2024/ai-perception-gap-introducing-my-new-blog/">wrote</a> earlier, my fellow backpackers consistently responded to my AI ambitions with a chorus of dystopian predictions. The pattern was always the same — educated twenty-somethings, raised in tech-savvy countries, all convinced that AI meant the end of the world. Through these conversations, two things became clear: AI was viewed by <strong>Gen Z</strong> as <strong>tomorrow’s problem</strong>, and <strong>tomorrow’s threat</strong>.</p>

<p>Two thousand miles north and <strong>a decade earlier</strong>, a different kind of AI story was already unfolding in Reading, Pennsylvania. In 2011, the city had a poverty rate of 41.3%, the highest in the USA. Inequality and crime were endemic in Reading’s society. With a growing need for greater policing capabilities, the force were instead forced to cut head count by forty-five officers due to the economic aftermath of the 2008 financial crisis. Desperation led police chief William Heim to hunt for efficiency gains and he found the perfect solution: an <strong>artificial intelligence system</strong> designed to <strong>increase police efficiency</strong>, <strong>reduce crime</strong>, and — rather impressively — <strong>remove human prejudice</strong> from policing. A year after deployment, Chief Heim was overjoyed to report massive efficiency gains. Yet beneath these impressive reports lay a troubling reality: the <strong>system was silently perpetuating discrimination</strong> against certain ethnic groups.</p>

<p>The gap between perception and reality is stark. In Mexico, travellers feared for AI <strong>catastrophes</strong> and they expected them <strong>tomorrow</strong>. Meanwhile, in Reading (and other cities in the USA and UK), an AI system built with <strong>noble intentions</strong> was silently reinforcing societal inequalities <strong>today</strong>. The true threat of AI isn’t in science fiction — it’s in the seemingly benign algorithms already operating in our communities.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_03_hostel_bar-480.webp 480w,/assets/img/blog/2025/apg_03_hostel_bar-800.webp 800w,/assets/img/blog/2025/apg_03_hostel_bar-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_03_hostel_bar.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A photo taken from a hostel rooftop with a view of the city and mountains in Oaxaca, Meixco" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>The view from a hostel's rooftop bar in Oaxaca, Mexico.</figcaption>
</figure>

<h2 id="readings-digital-police-force">Reading’s Digital Police Force</h2>

<h3 id="predpol-birth-of-an-algorithm">PredPol: Birth of an Algorithm</h3>

<p>Reading’s police force wasn’t seeking a technological revolution — they were simply trying to survive budget cuts. What they got was a <strong>crime prediction</strong> software — from California big data start-up, PredPol — that transformed their city into a grid of colour-coded, sports pitch-sized cells, with each cell’s colour corresponding to the probability of crime occurrence. The logic was compelling: <strong>let AI direct a smaller police force to where they’re needed most</strong>, maintaining public safety despite budget cuts.</p>

<p>Beyond efficiency gains, PredPol promised to <strong>revolutionise the fairness</strong> of policing itself. Human officers, shaped by years of media exposure and societal influences, inevitably carry unconscious biases that can affect their policing decisions. By replacing human intuition with AI-driven deployment, Reading police could <strong>eliminate human bias</strong>. PredPol’s designers built their system on just two neutral features: the location and timing of previous crimes. The individuals behind these crimes, as well as their <strong>race</strong> and <strong>ethnicity</strong>, were <strong>deliberately excluded</strong> from the algorithm, in what the designers trumpeted as a foolproof safeguard against bias.</p>

<hr class="dots" />

<h3 id="numbers-dont-lie-or-do-they">Numbers Don’t Lie (Or Do They?)</h3>

<p>The system was immediately successful with <strong>burglaries in Reading down by 23%</strong> within a year of deployment. PredPol’s success quickly resonated beyond Reading’s borders. In 2013, <strong>police in Kent, UK</strong>, adopted PredPol’s system and within a year reported its targeted predictions to be <strong>ten times more effective than random patrolling</strong>. The system’s elegant interface made it instantly accessible to officers and it seemed to deliver on its promise of fairer policing, replacing human intuition with data-driven decisions.</p>

<p>On paper, it seemed flawless. A data-driven system making objective decisions based purely on time and location. But as we’ll see, this apparent success story would reveal one of AI’s most insidious capabilities: the power to <strong>automate and amplify existing social biases while maintaining an illusion of objectivity</strong>.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_03_numbers-480.webp 480w,/assets/img/blog/2025/apg_03_numbers-800.webp 800w,/assets/img/blog/2025/apg_03_numbers-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_03_numbers.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A photo of a laptop with a series of green numbers reflecting the running of an algorithm" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

</figure>

<h3 id="beneath-the-algorithm">Beneath the Algorithm</h3>

<p>Before we dig into PredPol’s mistakes, here’s a quick technical lesson. AI systems are like young children learning to play a game: they are given an <strong>objective</strong> (what to achieve) and <strong>training data</strong> (examples to learn from). They analyse the examples (often millions of them) to learn how to achieve the objective.</p>

<h4 id="the-devil-in-the-data">The Devil in the Data</h4>

<p>Consider the simple example of chess. After analysing millions of games, AI learns which sequences of moves increase the likelihood of winning. If two chess players whom never learned that knights can jump over other pieces played millions of games, the resulting dataset would hide one of chess’s powerful tactics. Any AI learning from this data would be blind to the power of a knight in defence and attack. AI simply cannot learn patterns it is not exposed to (some AI systems actually can learn unseen patterns, but the technology used by PredPol cannot).</p>

<p>Imagine two identical crimes: one committed in a heavily policed, disadvantaged neighbourhood, the other in an affluent area with minimal police presence. The first crime becomes a data point, the second remains invisible to the system. Multiply this effect across decades of policing, and you have a <strong>dataset that paints certain communities as inherently criminal</strong> while others appear crime-free. PredPol’s system can’t learn about crime patterns in areas where historical data is sparse. Instead, it simply reinforces existing patrol patterns, guiding police to the same disadvantaged communities which in turn produces more crime data points, creating a self-perpetuating cycle of surveillance and enforcement.</p>

<h4 id="predpols-flawed-goals">PredPol’s Flawed Goals</h4>

<p>The training data’s flaws were just the beginning. PredPol’s fundamental objective proved equally problematic. While a chess AI’s goal is trivial (to win the game), choosing an objective in real-world settings is often more nuanced. Consider a self-driving car with only one instruction: avoid collisions. The simplest way to achieve that? Never leave the garage. AI systems do exactly what they are trained to do, and <strong>PredPol trained their AI to maximise arrests by intelligently optimising police patrol</strong>.</p>

<p><strong>But do more arrests mean safer streets? Not necessarily.</strong> The system’s singular focus on sending officers where arrests are likely just reinforces old patterns. Real policing isn’t just about cracking down — it’s about building trust, keeping communities safe before crimes happen. The role of a <strong>data scientist</strong> is to <strong>encode qualitative objectives</strong> like trust numerically (an extremely difficult challenge), thereby allowing an AI system to reflect real-world objectives. Instead, model designers at PredPol took the <strong>easy route</strong> and used the numerically available objective of arrests. Wealthy, degree-holding data scientists took the path of least resistance, and the cost of their convenience fell squarely on the poor.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_03_white_collar_crime-480.webp 480w,/assets/img/blog/2025/apg_03_white_collar_crime-800.webp 800w,/assets/img/blog/2025/apg_03_white_collar_crime-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_03_white_collar_crime.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A photo of a man in a suit with handcuffs to represent white-collar crime" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

</figure>

<h3 id="white-collar-dark-data-predpols-blind-spots">White Collar, Dark Data: PredPol’s Blind Spots</h3>

<p>Now imagine if this algorithmic intensity targeted <strong>white-collar crime</strong>.</p>

<p>In the 2000s, financial leaders orchestrated frauds that shattered the global economy, leaving millions without jobs, homes, and healthcare. These crimes, orchestrated from pristine offices rather than dark alleys, caused more devastation than any street offense PredPol was built to prevent. Yet from their <strong>training to their bulletproof vests</strong>, police are designed to <strong>operate on the streets</strong>, not in boardrooms. Agencies chasing white-collar crime — like the FBI — have struggled for years to get close to bankers. The finance industry’s wealth and powerful lobbies ensure it remains significantly underpoliced, while AI systems like PredPol’s continue directing resources towards already over-policed communities. Rich bankers dodged arrests in the past, wealthy data scientists craft AI systems that embed historical arrest patterns in the present, and disadvantaged communities continue to face discrimination in the future. Inequality becomes code, poverty becomes data — and Silicon Valley celebrates their “efficiency gains’’ over $200 bottles of Dom Pérignon.</p>

<hr class="dots" />

<h2 id="the-price-of-automated-policing">The Price of Automated Policing</h2>

<p>Back in that <strong>Mexican hostel bar</strong>, my fellow travellers painted vivid pictures of <strong>superintelligent machines rising against humanity</strong>. While they envisioned spectacular science fiction scenarios, <strong>real AI systems</strong> like PredPol’s had already been reshaping communities through the quiet power of <strong>algorithmic bias</strong> for a decade.</p>

<p>PredPol’s designers proudly built a system that <strong>ignored race and ethnicity</strong> and focused on geography instead. Yet in our highly segregated cities, they overlooked a critical detail: <strong>geography itself serves as a powerful proxy for race</strong>. The system dutifully directs officers to the same neighbourhoods, generating more arrests, creating more data points, and perpetuating a <strong>self-fulfilling prophecy of “high-crime areas”</strong>.</p>

<p>The AI challenge isn’t spotting killer robots; it’s developing the nuanced understanding needed to <strong>recognise and address hidden algorithmic biases</strong> before they become embedded in our social fabric. The future my fellow travellers feared may never come to pass, but the present they missed is <strong>already here</strong>.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_03_wmd.webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_03_wmd.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="Front cover of Weapons of Math Destruction" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>Cathy O'Neil's book <a href="https://www.goodreads.com/book/show/28186015-weapons-of-math-destruction">Weapons of Math Destruction</a>.</figcaption>
</figure>

<h2 id="appendix---weapons-of-math-destruction">Appendix - Weapons of Math Destruction</h2>

<p>Mathematics Ph.D. graduate <a href="https://cathyoneil.org/">Cathy O’Neil</a> coins the term <em>Weapons of Math Destruction (WMDs)</em> to describe mathematical models like PredPol’s. WMDs are designed with the very best intentions but due to misunderstandings during design, they unintentionally punish the poor, incease inequality, and threaten democracy. They operate in bulk and are cheap to run, hence, multiplying the negative impact on society. To learn about more examples of WMDs in credit scoring, insurance applications, and job hunting, I point you to O’Neil’s New York Times best-seller <em><a href="https://www.goodreads.com/book/show/28186015-weapons-of-math-destruction" style="color: var(--global-theme-color);">Weapons of Math Destruction;</a></em> Chapter 5 of which is about PredPol!</p>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[An AI system designed to nullify human prejudice from the police force ended up reinforcing and exacerbating the very inequalities it was meant to overcome.]]></summary></entry><entry><title type="html">AI Perception Gap: How AI is Revolutionising the Hunt for Critical Battery Metals</title><link href="http://localhost:4000/blog/2025/apg-blog-02/" rel="alternate" type="text/html" title="AI Perception Gap: How AI is Revolutionising the Hunt for Critical Battery Metals" /><published>2025-01-06T05:40:16+00:00</published><updated>2025-01-06T05:40:16+00:00</updated><id>http://localhost:4000/blog/2025/apg-blog-02</id><content type="html" xml:base="http://localhost:4000/blog/2025/apg-blog-02/"><![CDATA[<h2 id="the-problem">The Problem</h2>

<p>The race towards a greener future — dependent on battery production and the electric vehicle (EV) revolution — hinges on four critical elements from the periodic table: <strong>Copper, Lithium, Cobalt, and Nickel</strong>. But why these four?</p>

<ul>
  <li><strong>Copper</strong> — the workhorse of a battery — powers the flow of electricity by carrying electrons in almost all electricity applications. An EV requires <strong>three times as much</strong> copper (by mass) compared to an equivalent internal combustion car (a petrol-fuelled vehicle).</li>
  <li><strong>Lithium</strong> is the most desired anode material in a battery. It’s the lightest metal and has a high propensity to lose an electron, which is necessary to produce energy within the battery. Alternatives like sodium-ion batteries are far less effective in comparison: sodium’s mass is three times that of lithium, and its reluctance to lose electrons results in significantly less energy per unit of mass. Simply put, <strong>lithium is the lifeblood of EV batteries</strong>!</li>
  <li><strong>Cobalt</strong> and <strong>nickel</strong> are the best cathode materials since their chemical properties make them great receivers of electrons. While cobalt delivers peak battery performance, nickel has emerged as the preferred substitute due to cobalt mining practices. Over 60% of the world’s cobalt supply comes from mines in the Democratic Republic of Congo, where many mines force children in their early teens to work in horrendous conditions. Furthermore, Russia is the second biggest producer of both cobalt and nickel. The ethical and political urgency of discovering alternative deposits of both metals is undeniable.</li>
</ul>

<p>But here’s the crux: <strong>we don’t have enough metal to meet skyrocketing demand</strong>. Experts predict a <strong>$15 trillion supply gap</strong> in these four metals by 2050 (based on March 2023 commodity prices). Yes, that’s <strong>$15 trillion worth of new discoveries</strong> needed (after we’ve mined all known deposits first).</p>

<p>By 2050, <strong>demand</strong> is forecasted to explode — <strong>30x for lithium, 15x for cobalt, 5x for nickel, and 2x for copper</strong> (a massive increase considering copper is already a $100bn market).</p>

<p>Meanwhile, <strong>supply</strong> is dwindling. Imagine fishing in the same pond for decades. Eventually, the big fish run out. The small ones aren’t economically worthwhile. You’re forced to either stop fishing or find a new pond.</p>

<p>That’s where we are with metals. For centuries, we’ve mined just the top one-hundred meters beneath the surface because these deposits are easier to discover and extract. Now that these deposits have diminished, we’re left with no choice but to dig deeper. But, our old discovery techniques no longer suffice in this uncharted territory; we need new methods to fish for metals at greater depth.</p>

<p>Enter <a href="https://www.KoBoldmetals.com">KoBold Metals</a>, a Silicon Valley-based startup founded in 2018 to tackle the bottleneck threatening the battery metals revolution. Their mission? To revolutionize mineral exploration by looking <strong>hundreds, even thousands</strong> of meters below Earth’s surface. And the key to their strategy? <strong>AI-powered exploration</strong>.</p>

<hr class="dots" />

<h2 id="exploration-in-a-toy-example">Exploration in a Toy Example</h2>

<p>Before we focus on all things KoBold, let’s begin with a <strong>simple example</strong>…</p>

<h3 id="aim">Aim</h3>

<p>Your goal is to create a map of a region no one has ever visited before. You must <strong>predict</strong> the class (sea, forest, sand dune, etc.) of the terrain at various points. All you have at your disposal is a plane, 4 parachute jumpers, and devices enabling the crew to communicate.</p>

<h3 id="prior-knowledge">Prior Knowledge</h3>

<p>You begin by flying the plane at 10,000m; traversing the whole region like a counter advancing through a snakes and ladders board. At this altitude, your ability to make confident predictions is limited. Hence, you assign subjective probabilities to regions: “I predict the big blue region is the sea and I am 98% confident.” Here, you made a <em>prediction</em> (sea) and indicated your <em>confidence</em> in your prediction (98%). Are the white regions snow, sand dunes, or salt flats? White regions immediately beside the sea are more likely to be sand dunes than anything else. Moreover, snow is more likely to be found at higher altitudes, so you look for mountains when distinguishing from salt flats. After flying over the entire region, you create a first draft of the map with your team. In some parts you’re very confident, others you’re not. How do you increase the confidence in your observations?</p>

<h3 id="field-mapping">Field Mapping</h3>

<p>Of course, you drop the 4 parachuters! As they fall, the radius of their visual field shrinks but they become more confident in their predictions. We call an increase in confidence a <strong>reduction in uncertainty</strong>.</p>

<p>Why keep each parachuter’s belief separate from one another? If all 4 parachuters can all see the same green region during their fall and they all predict it is a grassland, your team can confidently predict grassland on the map. If you spread the parachuters over the entire map and each region can only be observed by 1 team member, there would be more uncertainty in each of your predictions. Now, a trade-off exists: spread the parachuters out (resulting in non-overlapping views) to cover a more expansive area but have less confidence in your conclusions, or cover less area but have more confidence in your conclusions. Does an optimal strategy exist?</p>

<p>Most likely! Prior to dropping the parachuters, you can use the draft map of the world (called your <em>prior knowledge</em>). Recall, your prior is confident that the blue region visible from the plane is the sea. Is it wise to drop parachuters there? No, of course not! You’re already confident after all. Dropping your team where uncertainty is greatest (confidence is low) is optimal. You want each resource (each parachuter) to provide as much new information as possible.</p>

<p>The overarching principle is: build a <strong>prior knowledge</strong> of the world using all tools at your disposal, then <strong>decrease your uncertainty</strong> as much as possible through exploration with the <strong>limited resources</strong> you have.</p>

<hr class="dots" />

<h2 id="exploration-at-kobold-metals">Exploration at KoBold Metals</h2>

<h3 id="aim-1">Aim</h3>

<p>KoBold Metals’ aim is to efficiently use their resources to create a highly informative map. In their case, their map must indicate the presence of metals beneath the surface.</p>

<h3 id="prior-knowledge-1">Prior Knowledge</h3>

<p>In the previous example, the map represented visible light and the only measuring device employed was the human eye. Of course, KoBold use tools far more capable than the human eye and they use data types far more informative than visual light. The types of data they collect to build their prior knowledge are:</p>

<ul>
  <li><strong>Spectral imagery</strong>: Spectral imagery can be visible light, UV light, infrared light, and more.</li>
  <li><strong>Magnetic</strong>: Anomalies in magnetic maps that cannot be explained by Earth’s magnetic field alone can indicate the presence of metal.</li>
  <li><strong>Radiometrics</strong>: Rocks are continuously decaying and emitting radioactive decay products. Certain products can indicate the presence of certain metals.</li>
  <li><strong>Electromagnetic</strong>: Provides information about the conductivity of the surface. An electromagnetic sensor emits electromagnetic waves into the ground or rocks. These waves induce currents in conductive materials beneath the Earth’s surface and the sensor measures the secondary electromagnetic fields generated by these currents.</li>
  <li><strong>Gravity</strong>: Anomalies in gravity maps that cannot be explained by Earth’s gravitational field alone can indicate the presence of metal. Density of materials beneath the surface influence gravity readings above the surface because denser material creates a stronger gravitational attraction.</li>
</ul>

<p>This stage of the process is absolutely critical. When using AI, the real <strong>power lies in the data itself</strong>. AI may be a brilliant detective, capable of uncovering patterns present in large quantities of data, but it can only work with the clues it’s given. KoBold’s job? Plant those clues. By ensuring the <strong>data is rich, precise, and comprehensive</strong>, they lay the groundwork for AI to transform raw information into groundbreaking discoveries.</p>

<h3 id="field-mapping-1">Field Mapping</h3>

<p>KoBold is searching for metals across five continents, but here I focus on their exploration at a site in Quebec, Canada. The Cape Smith Belt, Quebec, is a complex geological structure comprised of a variety of rocks over 1.9 billion years old. It is an extremely remote and beautiful area, making it a popular destination for hiking, camping, and fishing. The remote location imposes immense challenges in terms of logistics and cost. Everything — drilling equipment, personnel, survival supplies, etc. — must be flown in. Moreover, all samples taken by drilling into the rock must be flown out for testing. The climate presents further challenges: there’s snow on the ground nine months a year, leaving only three months to collect samples.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_02_cape_smith_belt-480.webp 480w,/assets/img/blog/2025/apg_02_cape_smith_belt-800.webp 800w,/assets/img/blog/2025/apg_02_cape_smith_belt-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_02_cape_smith_belt.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A helicopter and mineral explorers in a remote rocky area" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>The Cape Smith Belt, Quebec, Canada. Image credit: Dr. Kurt House, KoBold Metals CEO. See slide 34 <a href="https://youtu.be/ERjBgQuyJ7A?si=G2mMCFaxUV6oYYEP&amp;t=1969">here</a>.</figcaption>
</figure>

<p>Across a 1000 km<sup>2</sup> (200,000 acres) region searched by KoBold Metals, only <strong>5 tonnes of samples</strong> were collected during an intensive three-month campaign. To put this in perspective: the rock samples gathered amount to the mass of just four hatchback cars, collected from a region comparable to 98,000 football (soocer) pitches — crazy! Hence, it is vital to be highly efficient. Explorers must collect the most informative type of information in the most informative locations.</p>

<p>In the image below, we see the <em>prediction</em> and <em>uncertainty</em> of KoBold’s prior knowledge on the left (<em>Day 1 prediction</em> and <em>Day 1 uncertainty</em>). After drilling at four locations (shown by four black dots in <em>Day 1 uncertainty</em>), KoBold updated their prediction and uncertainty, shown in <em>Day 30 prediction</em> and <em>Day 30 uncertainty</em>. They classify each region into one of three classes (Basalt, Gabbro, Peridotite), similar to spotting sand dunes, salt flats, and sea in the toy example. Here, each class is represented by green, blue, or red, as shown by the <em>prediction</em> plots.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2025/apg_02_uncertainty-480.webp 480w,/assets/img/blog/2025/apg_02_uncertainty-800.webp 800w,/assets/img/blog/2025/apg_02_uncertainty-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2025/apg_02_uncertainty.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="A series of maps demonstrating conclusions and uncertainty" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>KoBold's prediction and uncertainty at the Cape Smith Belt before and after field mapping. Image credit: Dr. Kurt House, KoBold Metals CEO. See slide 35 <a href="https://youtu.be/ERjBgQuyJ7A?si=G2mMCFaxUV6oYYEP&amp;t=2019">here</a>.</figcaption>
</figure>

<p>As in the toy example, where you chose not to drop parachute jumpers in an area you were highly confident was the sea, KoBold Metals were guided by the uncertainty in their prior knowledge. The drilling locations they selected, shown by the four black dots in <em>Day 1 uncertainty</em>, clearly lay in regions of high uncertainty (areas of yellow). Their confidence at these very locations improves tremendously, as evidenced by the low-uncertainy blue on the <em>Day 30 uncertainty</em> plot. Furthermore, the dominant colour of the uncertainty plot switches from yellow to green after the field mapping, suggesting uncertainty has been reduced throughout the region. This decrease in uncertainty is also evident on the prediction plots. The <em>Day 30 prediction</em> plot appears to be a less blurry version of the <em>Day 1 prediction</em> plot, with well-defined areas of blue, red, and green. Essentially, a reduction in uncertainty provides, quite literally, a clearer image of the minerals in the exploration region.</p>

<hr class="dots" />

<h2 id="the-big-picture">The Big Picture</h2>

<p>I have simplified the entire exploration process significantly here. There are many scientific challenges KoBold face throughout their search for mineral deposits. To learn more about the end-to-end process, watch the video below or listen to Kurt’s appearance on a podcast <a href="https://open.spotify.com/episode/6sQljIZbhC1u7Kn2ARKs1m?si=5a9c22567bca4851">here</a>.</p>

<figure class="post-figure">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ERjBgQuyJ7A?si=KtJxUY8DrMYmPoCT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</figure>

<h2 id="have-kobold-metals-been-successful">Have KoBold Metals Been Successful?</h2>

<p>Yes! In 2024, they announced their first major discovery: a colossal copper deposit in Zambia. <a href="https://www.lusakatimes.com/2024/02/06/kobold-metals-unveils-monumental-copper-discovery-in-zambia/">This</a> article states it’s the largest copper deposit ever recorded in Zambia and <a href="https://www.linkedin.com/pulse/kobold-metals-uncovers-large-copper-deposit-zambia-using-s602c/">this</a> article suggests the mine contains enough copper to produce 100 million of today’s average-size electric vehicle batteries.</p>

<p>I think stories like this are so incredible. Kurt House launched a startup to approach mineral exploration differently. They built their workforce to be comprised of tens and tens of data scientists — unprecedented in the industry. Then after years of trusting their process, with collaboration across disciplines between geoscientists and data scientists, they struck gold. I voiced my admiration for their discovery when I met Kurt during my <a href="https://ben-j-barlow.github.io/blog/2024/my-msc-dissertation/">trip</a> to Stanford in June 2024. His response was typical of a leader on a mission: “Thanks. Onto the next.”</p>

<hr class="dots" />

<h2 id="a-note-on-sustainability">A Note on Sustainability</h2>

<p>I know what the sustainability-minded amongst us are thinking…support the green revolution by building additional mines and further disrupting the beautiful planet. Some contradiction. Here’s the situation…</p>

<p>Drilling for fossil fuels and burning them to produce energy is a singular economy. Carbon is released into the atmosphere where it remains for a significantly long time. Whereas, drilling for metals to produce EV batteries can facilitate a circular economy on a gigantic scale. It’s possible to achieve a 98% or more recycling rate on the metals contained in batteries; high enough to almost stop mining metal altogether! But, we must extract the metals from the ground and funnel them into the system first. This will take 50 years or so — hold tight!</p>

<p>While the extraction of battery metals is a positive step for green energy and combating climate change, the term sustainability encompasses more than just carbon emissions. Mining disrupts ecosystems, which no amount of reduction in emissions can bring back. Thus, KoBold’s work doesn’t have a wholly positive impact. This is where my friends with academic backgrounds in philosophy and environmental studies can take over…bye for now.</p>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[Explore how AI-powered mineral discovery is bridging the $15 trillion gap in metals critical to the green revolution.]]></summary></entry><entry><title type="html">AI Perception Gap: From Tragedy to Closure — How AI Identified Plane Crash Victims</title><link href="http://localhost:4000/blog/2024/apg-blog-01/" rel="alternate" type="text/html" title="AI Perception Gap: From Tragedy to Closure — How AI Identified Plane Crash Victims" /><published>2024-12-06T08:40:16+00:00</published><updated>2024-12-06T08:40:16+00:00</updated><id>http://localhost:4000/blog/2024/apg-blog-01</id><content type="html" xml:base="http://localhost:4000/blog/2024/apg-blog-01/"><![CDATA[<h2 id="the-story-behind-the-crash">The Story Behind The Crash</h2>

<h3 id="introduction">Introduction</h3>

<p>On July 17, 2014, a Malaysian Airlines passenger jet was shot down on its journey from Amsterdam Schiphol Airport to Kuala Lumpur. The plane was flying through Ukrainian airspace, 50 km from the Russian border, when it was struck by a surface-to-air missile over a region controlled by Russian-backed separatists during the war in Donbas. 298 victims were tragically killed. Identifying and returning body parts to loved ones was a formidable challenge as unidentified human remains (UHR) were dispersed over a 50 square kilometre region. Meanwhile, heartbroken families across the globe were grieving. Aware that each passing day without a burial added to the immense trauma experienced by the victims’ families, investigators looked to AI to help with returning UHR to loved ones as quickly as possible.</p>

<figure class="post-figure">
    <video width="" height="" controls="">
        <source src="https://upload.wikimedia.org/wikipedia/commons/9/99/MH17_Missile_Impact.webm" type="" />
        Your browser does not support the video tag.
    </video>
    <figcaption>Narrated 3D animation reconstructing the missile's impact on the aircraft. Licensed under <a href="https://creativecommons.org/licenses/by/3.0/deed.en">CC-BY (3.0)</a> by the <a href="https://en.wikipedia.org/wiki/Dutch_Safety_Board">Dutch Safety Board</a>.</figcaption>
</figure>

<h3 id="the-challenges">The Challenges</h3>

<p>Investigators at the Netherlands Forensic Institute (NFI) were tasked with the difficult identification process. Frustratingly, they faced a number of obstacles.</p>

<ol>
  <li><strong>DNA quality</strong>: Fire and explosions during the crash meant remains were heavily burned, thereby degrading DNA.</li>
  <li><strong>Site accessibility</strong>: The remains were spread across an active war zone which presented obvious accessibility issues. Body parts continued to arrive in the Netherlands for 10 months.</li>
  <li><strong>DNA history</strong>: Investigators lacked prior records of the victims’ DNA, as they were not part of any criminal database. Identification had to be performed by DNA comparison with relatives. DNA donations were limited in some cases due to the death of immediate family in the crash or a lack of contact with other family members.</li>
  <li><strong>Volume</strong>: Matching body parts by DNA requires a number of comparisons proportional to the square of the total body parts needing identification. 10 victims in a Blue Wing Airlines crash on April 3, 2008, were identified by manual DNA comparisons. This took 2 days by hand. However, with 298 victims, investigators at NFI faced the monumental task of making millions of DNA comparisons—a scale that made manual efforts entirely impractical.</li>
</ol>

<p>The investigators needed a comparison-based identification framework that offered flexibility in terms of the number of DNA donations and the relationship of the donor. Most importantly, the system had to perform identifications as fast as possible!</p>

<hr class="dots" />

<h3 id="the-solution">The Solution</h3>

<p>Fortunately for the NFI, they had a state-of-the-art forensic software system—named Bonaparte—developed by a team at Radboud University in Nijmegen, Netherlands, during the mid-2000s. The system, which was designed to facilitate quick human DNA-based identification, was the perfect solution for the investigation as it overcame the challenges presented above. It enabled the identification of body parts even in the limited setting of partial DNA matches due to fires; it facilitated DNA donations from multiple family members with great flexibility offered in terms of relationship with the victim (the more distant the relation, the less similar the DNA); and the digital nature of the system permitted 1000s of DNA comparisons in minutes.</p>

<p>After analysing 6,000+ UHR body fragments and 500+ reference samples from relatives, 294 of the 298 victims had been identified within four months of the crash. Another two victims have since been identified, whilst the remaining two have sadly vanished without a trace.</p>

<figure class="post-figure">
    <img src="/assets/img/blog/convoy_of_cars.jpg" alt="A wall in the University of Edinburgh's School of Informatics stating their research began in 1963" />
    <figcaption>A convoy of cars carrying victims of the crash.</figcaption>
</figure>

<h2 id="the-technology">The Technology</h2>

<h3 id="identification-by-cause-and-effect">Identification by Cause and Effect</h3>

<p>Consider the sentence: “10-year-old Ben Barlow hit the football towards his grandparents’ window and the window smashed.” To the great annoyance of my grandad, who was celebrating his 70th birthday at the time, this statement holds true. After observing the cause (Ben kicks the ball), we can estimate the probability of the effect (the window smashed). Human cognition works in this direction.</p>

<p>But, given the effect “the window smashed” (and my grandad spent the afternoon of his birthday boarding up a window whilst all the family went out to celebrate), we need much more information to deduce the cause (who kicked the ball that broke it or even the fact that it was broken by a ball in the first place). Human cognition struggles to work in this direction.</p>

<p>This cognitive asymmetry was overcome in the 1700s when theologian Thomas Bayes proposed a new rule to employ when working with probabilies. Using the rule—now known as Bayes’ Theorem—one can work in the natural cognitive direction by estimating the probability of the effect given the cause, and use mathematical tools to infer the probability of the cause having observed the effect. This process is referred to as <em>inverse probability</em>.</p>

<p>Now, in the context of identifying human remains: If person A and person B are the mother and father of person C (the cause), then matches will exist if we compare the DNA of the child with its parents (the effect).</p>

<figure class="post-figure">
    <img style="width: 40%;" src="/assets/img/blog/graph2-1.png" alt="A graph with 2 parent nodes connecting to 1 child node, representing human parent-child relationships" />
    <figcaption>The DNA cause-effect relationships between parents and a child.</figcaption>
</figure>

<p>Expanding on the network of three nodes and two arrows, Bonaparte built much bigger networks (entire family trees). This allowed DNA donations from cousins, aunts, and other relatives, not just parents. When comparing all relations, Bonaparte was given the effect and used inverse probability to determine the probability of the cause.</p>

<figure class="post-figure">
    <img style="width: 60%;" src="/assets/img/blog/graph-2-1.png" alt="A graph with 2 parent nodes connecting to 1 child node, representing human parent-child relationships" />
    <figcaption>The DNA cause-effect relationships in a family tree.</figcaption>
</figure>

<p>A single UHR fragment was identified by the investigators by iterating through all 298 pedigree trees built using Bonaparte, entering the fragment’s DNA into each tree and observing the probability of the cause given the effect. By considering the trees that offered the maximal probability of the cause, the body part could be identified.</p>

<hr class="dots" />

<h3 id="the-story-behind-the-technology-how-neuroscience-can-inspire-ai">The Story Behind The Technology: How Neuroscience Can Inspire AI</h3>

<p>Bonaparte proved to be an indispensable tool for the investigators. It offered flexibility in the number of DNA donations and the relationship of the donor whilst possessing the ability to infer the probability of the cause after being provided the effect. This was all made possible by the technology that underpinned Bonaparte: Bayesian networks.</p>

<p>Over two centuries after Thomas Bayes’ (1702 - 1761) work on cause and effect, along came Israeli-American computer scientist and philosopher Judea Pearl (1936 - present). Whilst you may not be familiar with Pearl, you’ve likely heard the phrase “correlation, not causation”. Pearl spent his academic career developing mathematical tools for causal reasoning; we can now make “X causes Y” conclusions rather than being limited to “X correlates with Y”. During his academic journey, Pearl invented Bayesian networks and because of their dependence on inverse probability, Pearl honoured Bayes by naming the framework after him.</p>

<p>Pearl’s breakthrough was a prime example of how neuroscience can inspire AI. His eureka moment came in the mid-80s whilst reading an article by David Rumelhart: a cognitive scientist at University of California, San Diego. The article highlighted when humans read, we first recognise lines and circles which we combine to form letters; these combine to form words at the lexical level which are passed to the syntactic level. It is here, for example, that we decide to expect a noun to follow the word “the”. Finally, we reach the semantic level, where we remember the previous sentence referenced a Volkswagen, so we predict the noun following “the” could be “car”. Climbing the ladder is permitted by information moving through layers of neurons in the brain.</p>

<p>All the while, information gets propagated down the neural ladder too. When we struggle to read poor handwriting, the syntactic and semantic levels provide context, which helps us recognise messy shapes, letters, and words. The key here is neurons in the brain are passing information in both directions (from the top down and the bottom up) and from side to side. A change in belief in one neuron has the ability to affect the state of all other neurons.</p>

<p>Pearl was convinced that for computers to reason well under uncertainty, they must adopt a structure similar to that of human neural information processing. It took Pearl a few months to figure out that messages between layers should consist of forward probabilities and inverse probabilities computed using Bayes’ framework. By the late 1980s, his students and colleagues had helped him create a tool that would accelerate the world of machine learning.</p>

<p>In 2011, Pearl won the Turing Award—the highest distinction in computer science—for “fundamental contributions to artificial intelligence through the development of a calculus for probabilistic and causal reasoning”. Without his contributions, the field of AI would be lacking many of the tools it has available today, and the families of the plane crash victims would likely have waited much longer to bury their loved ones, or not even been able to bury them at all.</p>

<hr class="dots" />

<h2 id="appendix---a-note-on-ai">Appendix - A Note On AI</h2>

<p>As discussed in <a href="/blog/2024/ai-perception-gap-introducing-my-new-blog/">AI Perception Gap: Introducing my new blog!</a>, my goal is to close the <em>AI Perception Gap</em>. In June 2023, whilst writing this blog in Valencia, my flatmate asked, ‘Artificial intelligence isn’t here yet, is it?’ Well, every day I walk past a sign which reads “Celebrating 60 years of research in computer science and AI at the University of Edinburgh.” <a href="https://informatics.ed.ac.uk/60-years-computer-science-ai#:~:text=The%20University%20of%20Edinburgh%20traces,Michaelson%20was%20appointed%20its%20Director">This</a> announcement states, “the University of Edinburgh traces the origins of its activities around AI to a small research group established in 1963”. AI has existed for decades, with Bayesian networks as an example of 1980s technology that remains state-of-the-art today.</p>

<figure class="post-figure">
    <img src="/assets/img/blog/informatics_wall.png" alt="A wall in the University of Edinburgh's School of Informatics stating their research began in 1963" />
    <figcaption>A wall in the University of Edinburgh's School of Informatics.</figcaption>
</figure>]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[Plane crash investigators identify 6000+ human fragments by harnessing neuroscience-inspired AI and centuries-old mathematics.]]></summary></entry><entry><title type="html">AI Perception Gap: Introducing my new blog!</title><link href="http://localhost:4000/blog/2024/ai-perception-gap-introducing-my-new-blog/" rel="alternate" type="text/html" title="AI Perception Gap: Introducing my new blog!" /><published>2024-12-05T00:00:00+00:00</published><updated>2024-12-05T00:00:00+00:00</updated><id>http://localhost:4000/blog/2024/ai-perception-gap-introducing-my-new-blog</id><content type="html" xml:base="http://localhost:4000/blog/2024/ai-perception-gap-introducing-my-new-blog/"><![CDATA[<p><strong>A blog created to educate, inspire, and reshape Gen Z’s perception of artificial intelligence and its applications.</strong></p><h3>Discovering the AI Perception Gap</h3><p>While backpacking Latin America during the summer of 2022, I became deeply aware of what I labelled the <em>AI perception gap</em><strong><em>. </em></strong>For 5 weeks, I listened to AI-oriented podcasts by day — on treacherous bus journeys, sea-side sunbeds and rainforest-based hammocks — and socialised in hostel bars by night. My ears were flooded with hope, optimism, and trust in AI from sunrise to sunset. After dark, however, I was inundated with negativity from backpacker after backpacker — irrespective of nationality. “<strong>Do you love Elon Musk?</strong>” “When are we all losing our jobs then, mate?” “I’ll blame you when the robots take over!” All are exclamations I heard in abundance when I told new friends my plan to pursue an MSc in Artificial Intelligence upon my return to the UK.</p><p>I honestly could not believe my ears. Educated individuals, from my very generation (not my grandparents!), who were born and raised in wealthy economies where AI is booming, and no one had a clue about the monumental positive impact the technology can and will have on society at a global scale! <strong>The perception gap was born…</strong></p><figure style="text-align: center;"><img width="90%" alt="" src="https://cdn-images-1.medium.com/max/1024/1*WRDbSbGiMcOjXoi3WUmSlA.jpeg" /></figure><h3>Addressing the AI Perception Gap</h3><p>What is the aim of my blog? Fix the perception gap by making my friends aware of the positive potential of AI!</p><p>I did so on an individual level in hostel bar after hostel bar during my travels. (Surprisingly, this didn’t make me the life of the party!) But with a blog, I can have a much more significant impact!</p><p>The overarching aim is to <strong>educate, inspire, and reshape Gen Z’s perception</strong>. I will highlight use cases of AI that have a positive impact on society (and some negatively impacting use cases too). If all goes to plan, the audience will learn that “AI” does not equate to “self-modifying systems (code-writing code) that are destined to take over the world and kill us all”.</p><h3>Blog’s Target Audience</h3><p><strong>For my friends!</strong> More specifically, “my friends” correspond to <strong>educated individuals</strong> (educated to degree level in a <strong>different discipline</strong>), from all over the world, with ages ranging from <strong>18 to 30</strong>.</p><h3>What is AI?</h3><p>AI. I hear it all the time! It’s become a buzzword every business seems to throw on its social channels in an attempt to gain traction.</p><p>For this blog, I will not cross hairs about specific AI sub-fields. Like seemingly every business out there — if there is cool machine learning, data science, deep learning, statistics, or one of many other subfields being used under the hood — I will just call it AI. Essentially, I will term any system that sits in the Venn diagram below “AI”.</p><figure style="text-align: center;"><img width="90%" alt="" src="https://cdn-images-1.medium.com/max/1024/1*jTox5PBdB7tonTosN0Oy8w.png" /><figcaption >Image credit: Dr. Amy McGovern, the University of Oklahoma. See <a href="https://ai-fall2023.ai2es.org/module-1-overview/module-1-ltopic-1/">here</a>.</figcaption></figure><h3>Let’s Begin</h3><p>Initially, I will post exactly <strong>one blog a month on the 6th of each month for 6 months</strong>. Starting 6th December 2024 and finishing 6th May 2025 (my birthday!).</p><p>In keeping with my Latin American theme, my first blog will discuss a story I discovered whilst reading Judea Pearl’s <em>The Book of Why</em> on a beanbag in a hostel atrium in San Cristobal, Mexico. I will discuss how artificial intelligence permitted the rapid return of human remains to their families following a plane shooting above the Russia-Ukraine border in 2014.</p><h3>Negative impacts of AI</h3><p>It must be noted that I am aware that AI has the potential to impact society negatively. Many pro-AI folks are blind to its destructive potential. Of course, risks exist! But, a plethora of risks didn’t stop the internet from booming a few decades ago. Adopters of the technology just learned to spot the risks (for example, online scams). I hope we’ll do the same as AI becomes more prevalent in society.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c2f12b136007" alt="">]]></content><author><name></name></author><category term="ai-perception-gap" /><summary type="html"><![CDATA[Introducing a blog that educates, inspires, and reshapes Gen Z’s perception of artificial intelligence.]]></summary></entry><entry><title type="html">My MSc Dissertation Project at Stanford University</title><link href="http://localhost:4000/blog/2024/my-msc-dissertation/" rel="alternate" type="text/html" title="My MSc Dissertation Project at Stanford University" /><published>2024-11-18T16:40:16+00:00</published><updated>2024-11-18T16:40:16+00:00</updated><id>http://localhost:4000/blog/2024/my-msc-dissertation</id><content type="html" xml:base="http://localhost:4000/blog/2024/my-msc-dissertation/"><![CDATA[<p><strong>Well, that was the coolest professional experience of my life…</strong></p>

<p>From delving into AI and critical minerals research with world-class experts to gatecrashing conferences littered with talent, my three weeks at Stanford were a whirlwind of fun and academic growth. Add in the California sunshine and a road trip in a convertible Mustang, and you have the recipe for an unforgettable academic adventure.</p>

<h2 id="pre-stanford">Pre-Stanford</h2>

<p>How on Earth did I–an AI student at the University of Edinburgh–end up spending the first three weeks of my dissertation working with academics on Stanford University’s campus?</p>

<p>It all kicked off with a lightbulb moment a year earlier. There I was, lounging on the sofa, when it hit me: I’d be investing hundreds of hours into a project next summer anyway, so why not aim high? If I could find a company or research group I was extremely passionate about, I could use my three month project as a trial period for a dream job or PhD, thereby informing my subsequent life decisions.</p>

<p>Fired up by this idea, I dove into research mode. After a week of looking far and wide, I struck gold: Silicon Valley startup KoBold Metals. Their mission to leverage data science for accelerating mineral discoveries had me absolutely captivated.</p>

<p>But the real jackpot? Discovering their academic research partner, <a href="https://mineralx.stanford.edu/">Mineral-X</a> at Stanford University, had a team member who’d previously studied in Edinburgh. I knew I’d found my perfect supervisor!</p>

<p>Fast forward through a winter of persistent emails and video calls, and by summer, I’d lined up my dream dissertation project in a topic that excited me at a world-leading university. A project marrying two fields; applying an AI technique to the domain of mineral exploration for the critical battery metals. Determined to squeeze every drop of opportunity from this chance, I self-funded a three-week trip to California.</p>

<hr class="dots" />

<h2 id="my-time-at-stanford">My Time at Stanford</h2>

<p>The experience was truly exceptional. AI research lab <a href="https://sisl.stanford.edu/">SISL</a>, which provide AI technical support to Mineral-X, provided a warm welcome, offering me a desk in their office. As a master’s student working on only my second ever research project, being surrounded by Stanford PhDs and post-docs was incredibly special.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2024/quad-480.webp 480w,/assets/img/blog/2024/quad-800.webp 800w,/assets/img/blog/2024/quad-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2024/quad.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2024/coffee-480.webp 480w,/assets/img/blog/2024/coffee-800.webp 800w,/assets/img/blog/2024/coffee-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2024/coffee.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2024/golf-480.webp 480w,/assets/img/blog/2024/golf-800.webp 800w,/assets/img/blog/2024/golf-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2024/golf.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>
<p style="width: 100%; margin-top: 10px; font-style: italic; color: #666; text-align: center;">Started my time on campus by taking in the iconic view from The Oval (left), before settling into a routine of enjoying my morning coffee on the balcony of SISL's office (centre) and ending the day with a well-earned trip to the university’s driving range (right).</p>

<p>Having access to world experts in POMDPs (the AI technique I was using) proved invaluable. SISL’s on-demand, in-person guidance significantly accelerated my progress. Beyond the office, they were lovely people too—kindly involving me in weekly ultimate frisbee, taking me to play soccer games with their friends, and freeing up time to grab a coffee/beer to chat in a relaxed setting.</p>

<p>As well as the academics I worked with directly, I met some incredible other people too. During my first week, I was thrilled to discover Mineral-X were hosting their annual symposium during my second week on campus. This gathering brought together industry leaders, heads of data science teams, and recent PhD graduates from around the world, all in one place. The opportunity to engage directly with such a diverse group of experts was truly invaluable.</p>

<p>Besides the professional gains, June in California is somewhat superior to June in Edinburgh. Downtime was spent enjoying rounds at Stanford University Golf Course or supporting the Three Lions in the European Championships at a local English pub. To conclude the trip, I took a two-day, Top Gear-style drive, drifting across empty roads with amazing views in a convertible Mustang. I explored San Francisco’s bustling streets; crossed the Golden Gate Bridge; snapped pictures of Bay Area views; and rounded it off by drinking a bottle of red from Sonoma Valley in Sonoma Valley itself.</p>

<figure class="post-figure">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      <source class="responsive-img-srcset" srcset="/assets/img/blog/2024/mustang-480.webp 480w,/assets/img/blog/2024/mustang-800.webp 800w,/assets/img/blog/2024/mustang-1400.webp 1400w," type="image/webp" sizes="95vw" />
    
    <img src="/assets/img/blog/2024/mustang.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    <figcaption>A stunning road between the Golden Gate and Sonoma Valley.</figcaption>
</figure>

<h2 id="reflection">Reflection</h2>

<p>I’ve ticked off a number of typical achievements in my life: from achieving top grades to being elected as 1st XI captain of the University of Warwick Men’s Football Club. However, sporting and academic achievements rarely bring me a sense of immense pride. After all, there is always someone with a better mark in academia and someone with more talent on the football pitch.</p>

<p>But, I know no one who had the initiative to set up a dissertation project that aligned with their passions with an external supervisor based at a university they were not enrolled at. This time, my experience was entirely unique, and the sense of pride was striking.</p>]]></content><author><name></name></author><category term="reflection" /><summary type="html"><![CDATA[A reflection on my dissertation project experience, in-particular my three week trip to California.]]></summary></entry></feed>